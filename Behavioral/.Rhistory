if (!require("BayesianFirstAid")) {install_github("rasmusab/bayesian_first_aid"); require("BayesianFirstAid")}  ## Bayes package to play with
if (!require("coda")) {install.packages("coda"); require("coda")}
if (!require("effsize")) {install.packages("effsize"); require("effsize")}    ## effect size
if (!require("PairedData")) {install.packages("PairedData"); require("PairedData")}  ## paired datasets
theta <- seq(0, 1, 0.1)
therta
theta
prior <- pmin(theta, 1-theta)/sum(pmin(theta, 1-theta))
prior
op <- par(mfrow = c(3,1))
plot(theta, prior, type = "h", xlab = expression(theta), ylab = expression(paste("p(", theta, ")")), main = "Prior")
lik <- theta               ## due to Bernoulli (z = 1, N = 1)
plot(theta, lik, type = "h", xlab = expression(theta), ylab = expression(paste("p(D|", theta,")")), main = "Likelihood (z = 1, n = 1)")
p_D <- sum(lik*prior)      ## evidence
post <- lik*prior/p_D      ## Bayes theorem
plot(theta, post, type = "h", xlab = expression(theta), ylab = expression(paste("p(", theta,"|D)")), main = "Posterior")
par(op)
theta <- seq(0, 1, 0.01)               ## possible parameter values
theta
prior <- dbeta(theta, 11, 11)          ## beta (11,11) density (alpha = 11, beta = 11)
p_DTheta <- theta^8*(1-theta)^18       ## likelihood z = 8 heads, N - z = 18 tails
p_DTheta
p_ThetaD <- dbeta(theta, 19, 29)       ## 8+11, 26-8+11
x11()
op <- par(mfrow = c(3,1))
plot(theta, prior, type = "l", xlab = expression(theta), ylab = expression(paste("d(",theta,")")), main = "Prior")
plot(theta, p_DTheta, type = "l", xlim = c(0,1), main = "Likelihood", xlab = expression(theta), ylab = expression(paste("p(D|", theta, ")")))
plot(theta, p_ThetaD, type = "l", xlim = c(0,1), main = "Posterior", xlab = expression(theta), ylab = expression(paste("p(", theta, "|D)")))
abline(v = c(0.261, 0.533), lty = 2, col = "gray")
arrows(0.261, 0.8, 0.533, 0.8, length = 0.05, code = 3, col = "darkgray")
text(0.4, 1.5, "95% HPD", cex = 0.9, col = "darkgray")
barplot(as.matrix(c(60, 40)), xlim = c(-0.8,2), main = "Parrot Bar Chart")
abline(h = 50, col = "red", lty = 2)
barplot(as.matrix(c(60, 40)), xlim = c(-0.8,2), main = "Parrot Bar Chart")
par(op)
barplot(as.matrix(c(60, 40)), xlim = c(-0.8,2), main = "Parrot Bar Chart")
par(mfrow = c(1))
par(mfrow = c(1,1))
barplot(as.matrix(c(60, 40)), xlim = c(-0.8,2), main = "Parrot Bar Chart")
abline(h = 50, col = "red", lty = 2)
legend("topleft", legend = c("correct", "incorrect"), pch = 22, pt.bg = c("black","gray"))
binom.test(60, n = 100)      ## frequentist version
## We can not reject H0.
## Bayesian version
set.seed(123)       ## we fix this since there is some simulation going on here (MCMC)
?bayes.binom.test   ## it uses a beta(1,1) prior (uninformative).
x <- seq(-0.5, 1.5, 0.001)    ## just for plotting the prior
plot(x, dbeta(x, 1, 1), type = "l", xlim = c(-0.5, 1.5), xlab = "p", ylab = "density", main = "Beta(1,1) Prior")
set.seed(123)
res.bin <- bayes.binom.test(60, 100)   ## Bayesian binomial test
res.bin
install_github("rasmusab/bayesian_first_aid");
require(rjags)
require(rjags)
.Platform$pkgType
load(rjags)
library(rjags)
rsq <- ss.reg / (ss.reg + ss.res)
library(foreign)
texas <- as.data.frame(read.spss("http://mprlab327.webfactional.com/amorris/stats/M142.sav"))
colnames(texas)
# ----- Problem 3 -----
ss.reg <- 59.69
ss.res <- 344.25
+
+
rsq <- ss.reg / (ss.reg + ss.res)
-.035 ^ 2
-.035 ^ 2
-1 ^ 2
(-1) ^ 2
(-.035) ^ 2
c(.179, .178, -.029, .121, .0884, -.0347, .105) ^ 2
rsq <- ss.reg / (ss.reg + ss.res)
N <- 361
J <- 7
ss.reg <- 59.69
ss.res <- 344.25
ms.reg <- ss.reg / J
ms.res <- ss.res / (N - J - 1)
f.stat <- ms.reg / ms.res
pf(f.stat, J, N - J - 1, lower.tail = F)
rsq.adj <- 1 - (1 - rsq) * (N - 1) / (N - J - 1)
see <- sqrt(ss.res / N)
var.res <- ss.res / (N - J - 1)
.0884 ^ 2
b <- .143 * 1.618 / 1.059
t.stat <- b / .038
?pt
2 * pt(t.stat, N - J - 1)
pt(t.stat, N - J - 1)
2 * pt(t.stat, N - J - 1, lower.tail = F)
.114 ^ 2
.073 ^ 2
.073 ^ 2 * N / (N - 1)
.073 ^ 2 * (N - 1) / N
t.stat <- b / se.b
b <- .115 * .114 / 1.059
# We need to calculate the standard error of the unstandarized coefficient by:
# std-error-b <- sqrt(std-error-estimate ^ 2 / (ss-SDO * (1 - coef-of-multicollinearity)))
se.estimate <- sqrt(ss.res / N)
# to get the ss-SDO, we square the standard deviation of SDO (to get variance)
# and then multiply by N. (We're assuming that SPSS isn't reporting the
# unbiased estimate of population standard deviation.)
ss.sdo <- (.114 ^ 2) * N
# note that (1 - coef-of-multicollinearity(sdo)) = tolerance(sdo),
# which is given
tol.sdo <- .843
# so:
se.b <- sqrt((se.estimate ^ 2) / (ss.sdo * tol.sdo))
t.stat <- b / se.b
2 * pt(t.stat, N - J - 1, lower.tail = F)
spcor.aa.ed <- (cor.aa.ed - cor.aa.sdo * cor.ed.sdo) / sqrt(1 - cor.ed.sdo ^ 2)
cor.aa.ed <- .091
cor.aa.sdo <- .173
cor.ed.sdo <- -.228
# That semi-partial correlation is a measure of the relationship between
# affirmative action opposition and education, controlling for the
# effect of SDO on education.
# It is calculated by:
spcor.aa.ed <- (cor.aa.ed - cor.aa.sdo * cor.ed.sdo) / sqrt(1 - cor.ed.sdo ^ 2)
# Power analysis
# (This is with no interaction - within-subjects one-way anova)
mean_yes = .5;
mean_no = .4;
sd = .35;
cor = .3;
cov = cor * (sd ^ 2);
#mean2a = .5;
#mean2b = .5;
n = 125
nTests = 1000
success = vector(mode = "logical", length = nTests)
for (i in 1:nTests) {
subjects <- mvrnorm(n, c(mean_yes, mean_no, mean_no),
matrix(c(sd ^ 2, cov, cov,
cov, sd ^ 2, cov,
cov, cov, sd ^ 2), nrow = 3))
my.df <- data.frame(subject = as.factor(rep(1:n, 3)),
condition = as.factor(rep(1:3, each = n)),
scr = as.vector(subjects))
fit <- ezANOVA(my.df, dv = scr, wid = subject, within = condition)
if (fit$ANOVA[1,5] < .05) {
success[i] = TRUE
}
}
require(MASS)
# Power analysis
# (This is with no interaction - within-subjects one-way anova)
mean_yes = .5;
mean_no = .4;
sd = .35;
cor = .3;
cov = cor * (sd ^ 2);
#mean2a = .5;
#mean2b = .5;
n = 125
nTests = 1000
success = vector(mode = "logical", length = nTests)
for (i in 1:nTests) {
subjects <- mvrnorm(n, c(mean_yes, mean_no, mean_no),
matrix(c(sd ^ 2, cov, cov,
cov, sd ^ 2, cov,
cov, cov, sd ^ 2), nrow = 3))
my.df <- data.frame(subject = as.factor(rep(1:n, 3)),
condition = as.factor(rep(1:3, each = n)),
scr = as.vector(subjects))
fit <- ezANOVA(my.df, dv = scr, wid = subject, within = condition)
if (fit$ANOVA[1,5] < .05) {
success[i] = TRUE
}
}
require(ez)
# Power analysis
# (This is with no interaction - within-subjects one-way anova)
mean_yes = .5;
mean_no = .4;
sd = .35;
cor = .3;
cov = cor * (sd ^ 2);
#mean2a = .5;
#mean2b = .5;
n = 125
nTests = 1000
success = vector(mode = "logical", length = nTests)
for (i in 1:nTests) {
subjects <- mvrnorm(n, c(mean_yes, mean_no, mean_no),
matrix(c(sd ^ 2, cov, cov,
cov, sd ^ 2, cov,
cov, cov, sd ^ 2), nrow = 3))
my.df <- data.frame(subject = as.factor(rep(1:n, 3)),
condition = as.factor(rep(1:3, each = n)),
scr = as.vector(subjects))
fit <- ezANOVA(my.df, dv = scr, wid = subject, within = condition)
if (fit$ANOVA[1,5] < .05) {
success[i] = TRUE
}
}
mean(success)
200 * .7
# Power analysis
# (This is with no interaction - within-subjects one-way anova)
mean_yes = .5;
mean_no = .4;
sd = .35;
cor = .3;
cov = cor * (sd ^ 2);
#mean2a = .5;
#mean2b = .5;
n = 140
nTests = 1000
success = vector(mode = "logical", length = nTests)
for (i in 1:nTests) {
subjects <- mvrnorm(n, c(mean_yes, mean_no, mean_no),
matrix(c(sd ^ 2, cov, cov,
cov, sd ^ 2, cov,
cov, cov, sd ^ 2), nrow = 3))
my.df <- data.frame(subject = as.factor(rep(1:n, 3)),
condition = as.factor(rep(1:3, each = n)),
scr = as.vector(subjects))
fit <- ezANOVA(my.df, dv = scr, wid = subject, within = condition)
if (fit$ANOVA[1,5] < .05) {
success[i] = TRUE
}
}
c(.235, .268, -.041, .091, .138, .077, .173) ^ 2
rm(list=ls())
N <- 361 # sample size
J <- 7 # number of predictors
ss.reg <- 59.69 # sum of squares of regression model
ss.res <- 344.25 # sum of squares of residuals
ms.reg <- ss.reg / J # mean-square regression
ms.res <- ss.res / (N - J - 1) # mean-square residuals
## 3a.
# What % of the variation in opposition to affirmative action can be explained
# by the other variables?
# The % of variance explained by all of them is R-squared, which is
# SS-reg / (SS-reg + SS-res), or...
rsq <- ss.reg / (ss.reg + ss.res) # .15
# The % of variance that can be explained by each predictor (NOT controlling
# for other variables) is the square of the zero-order correlations, or...
c(.235, .268, -.041, .091, .138, .077, .173) ^ 2
# in the order on the homework:
# .055 .072 .0017 .0083 .019 .0059 .030
# The % of variance that can be explained by each predictor (controlling for the
# effects of the other predictors on this predictor) is the square of the semi-partial correlation
# between opposition to affirmative action and the predictor (available in the output), or..
c(.179, .178, -.029, .121, .0884, -.0347, .105) ^ 2
# in the order on the homework:
# .032 .032 .00084 .015 .0078 .0012 .011
f.stat <- ms.reg / ms.res
# and get the p value by using the F distribution function...
pf(f.stat, J, N - J - 1, lower.tail = F)
rsq.adj <- 1 - (1 - rsq) * (N - 1) / (N - J - 1) # .13
var.res <- ss.res / (N - J - 1) # .98
.0884 ^ 2 # .0078
b.educ <- .143 * 1.059 / 1.618
# then, calculate a t statistic by t(N - J - 1) = b / std-error(b), pulling std-error(b) from the
# output, or...
t.stat.educ <- b.educ / .038
# finally, get the (2-tailed) p value by looking up this value in the t distribution
2 * pt(t.stat.educ, N - J - 1, lower.tail = FALSE) # .014
# p < .05; opposition to affirmative action can be predicted by education at an above-chance level
## 3g.
# Same explanation as above.
b.sdo <- .115 * 1.059 / .114
# As it's not in the output, this time we need to calculate the standard error of the unstandarized
# coefficient by:
# std-error-b <- sqrt(std-error-estimate ^ 2 / (ss-SDO * (1 - coef-of-multicollinearity)))
se.estimate.sdo <- sqrt(ss.res / N) # .98
se.estimate.sdo <- sqrt(ss.res / N) # .98
# to get the ss-SDO, we square the standard deviation of SDO (to get variance)
# and then multiply by N. (We're assuming that SPSS isn't reporting the
# unbiased estimate of population standard deviation.)
ss.sdo <- (.114 ^ 2) * N
# note that (1 - coef-of-multicollinearity(sdo)) = tolerance(sdo),
# which is given
tol.sdo <- .843
# so:
se.b.sdo <- sqrt((se.estimate.sdo ^ 2) / (ss.sdo * tol.sdo)) # .49
t.stat.sdo <- b.sdo / se.b.sdo # 2.18
2 * pt(t.stat.sdo, N - J - 1, lower.tail = FALSE) # .030
# p < .05; opposition to affirmative action can be predicted by SDO at an above-chance level
## 3h.
cor.aa.ed <- .091
cor.aa.sdo <- .173
cor.ed.sdo <- -.228
# This semi-partial correlation is a measure of the relationship between affirmative action
# opposition and education, controlling for the effect of SDO on education. It is calculated by:
spcor.aa.ed <- (cor.aa.ed - cor.aa.sdo * cor.ed.sdo) / sqrt(1 - cor.ed.sdo ^ 2) # .13
# Power analysis
# (This is with no interaction - within-subjects one-way anova)
mean_yes = .5;
mean_no = .4;
sd = .35;
cor = .3;
cov = cor * (sd ^ 2);
#mean2a = .5;
#mean2b = .5;
n = 140
nTests = 1000
success = vector(mode = "logical", length = nTests)
for (i in 1:nTests) {
subjects <- mvrnorm(n, c(mean_yes, mean_no, mean_no),
matrix(c(sd ^ 2, cov, cov,
cov, sd ^ 2, cov,
cov, cov, sd ^ 2), nrow = 3))
my.df <- data.frame(subject = as.factor(rep(1:n, 3)),
condition = as.factor(rep(1:3, each = n)),
scr = as.vector(subjects))
fit <- ezANOVA(my.df, dv = scr, wid = subject, within = condition)
if (fit$ANOVA[1,5] < .05) {
success[i] = TRUE
}
}
mean(success)
setwd('/Users/adam/Me/Psychology/Projects/StealPunish/Old/Code/git/Behavioral/Fiery Studies/Data/Lit3/Flatness.csv')
setwd('/Users/adam/Me/Psychology/Projects/StealPunish/Old/Code/git/Behavioral/Fiery Studies/Data/Lit3')
require(lme4);
require(lmerTest);
require(dplyr);
df <- read.csv('data.csv')
df.inflex <- df %>% filter(opType == 0)
model = glmer(choice ~ role * matchRound + (1 + role * matchRound | subject), family = binomial, data = df.inflex);
model_null = glmer(choice ~ role + matchRound + (1 + role * matchRound | subject), family = binomial, data = df.inflex);
summary(model)
anova(model, model_null)
require(lme4);
require(lmerTest);
require(dplyr);
df <- read.csv('data.csv')
#df.inflex <- df %>% filter(opType == 0)
df.inflex <- df
model = glmer(choice ~ role * matchRound + (1 + role * matchRound | subject), family = binomial, data = df.inflex);
model_null = glmer(choice ~ role + matchRound + (1 + role * matchRound | subject), family = binomial, data = df.inflex);
summary(model)
anova(model, model_null)
model = glmer(choice ~ role * matchRound + (1 + role * matchRound | subject), family = binomial, data = df.inflex);
model_null = glmer(choice ~ role + matchRound + (1 + role * matchRound | subject), family = binomial, data = df.inflex);
summary(model)
anova(model, model_null)
df <- read.csv('data.csv')
#df.inflex <- df %>% filter(opType == 0)
df.inflex <- df
model = glmer(choice ~ role * matchRound + (1 + role * matchRound | subject), family = binomial, data = df.inflex);
model_null = glmer(choice ~ role + matchRound + (1 + role * matchRound | subject), family = binomial, data = df.inflex);
summary(model)
anova(model, model_null)
df <- read.csv('data.csv')
#df.inflex <- df %>% filter(opType == 0)
df.inflex <- df
model = glmer(choice ~ role * matchRound + (1 + role * matchRound | subject), family = binomial, data = df.inflex);
model_null = glmer(choice ~ role + matchRound + (1 + role * matchRound | subject), family = binomial, data = df.inflex);
summary(model)
anova(model, model_null)
df <- read.csv('data.csv')
#df.inflex <- df %>% filter(opType == 0)
df.inflex <- df
model = glmer(choice ~ role * matchRound + (1 + role * matchRound | subject), family = binomial, data = df.inflex);
model_null = glmer(choice ~ role + matchRound + (1 + role * matchRound | subject), family = binomial, data = df.inflex);
summary(model)
anova(model, model_null)
rm(list=ls())
library("nlme")
sampledata <- NA
sampledata$subject <- rep(c(1:20),each=6)
sampledata$roi <- rep(c("RSTS","MPFC"),each=3,20)
sampledata$condition <- rep(c("High","Medium","Low"),40)
sampledata$value <- runif(120,1,100)
as.data.frame(sampledata) -> sampledata
sampledata
modelPE <- lme(value ~ condition*roi, random = ~1|subject, data = sampledata, method = "ML")
#model without
modelPE_base <- lme(value ~ condition+roi, random = ~1|subject, data = sampledata, method = "ML")
#model info
summary(modelPE)
anova(modelPE)
(AIC(modelPE)-AIC(modelPE_base))
modelPE <- lme(value ~ condition*roi, random = ~condition*roi|subject, data = sampledata, method = "ML")
modelPE <- lme(value ~ condition*roi, random = ~1+condition*roi|subject, data = sampledata, method = "ML")
summary(modelPE)
anova(modelPE)
setwd("~/Me/Psychology/Projects/StealPunish/git/Behavioral")
rm(list=ls())
df <- read.csv('data.csv')
df.inflex <- df %>% filter(opType == 0)
model = glmer(choice ~ role * matchRound + (1 + role * matchRound | subject), family = binomial, data = df.inflex);
model_null = glmer(choice ~ role + matchRound + (1 + role * matchRound | subject), family = binomial, data = df.inflex);
summary(model)
anova(model, model_null)
df <- read.csv('data.csv')
df.inflex <- df %>% filter(oppInflex == 1)
model = glmer(choice ~ roleVictim * matchRound + (1 + roleVictim * matchRound | subject),
family = binomial, data = df.inflex);
model_null = glmer(choice ~ roleVictim + matchRound + (1 + roleVictim * matchRound | subject),
family = binomial, data = df.inflex);
summary(model)
anova(model, model_null)
require(lme4);
require(lmerTest);
require(dplyr);
df <- read.csv('data.csv')
df.inflex <- df %>% filter(oppInflex == 1)
model = glmer(choiceAction ~ roleVictim * matchRound + (1 + roleVictim * matchRound | subject),
family = binomial, data = df.inflex);
model_null = glmer(choiceAction ~ roleVictim + matchRound + (1 + roleVictim * matchRound | subject),
family = binomial, data = df.inflex);
summary(model)
anova(model, model_null)
save.image("analyzed.RData")
df.inflex
View(df.inflex)
df.first <- df.inflex %>% filter(globalRound <= 24)
model2 = glmer(choiceAction ~ roleVictim * matchRound + (1 + roleVictim * matchRound | subject),
family = binomial, data = df.inflex);
summary(model2)
model2 = glmer(choiceAction ~ roleVictim * matchRound + (1 + roleVictim * matchRound | subject),
family = binomial, data = df.first);
summary(model2)
df.second <- df.inflex %>% filter(globalRound > 24)
model.second = glmer(choiceAction ~ roleVictim * matchRound + (1 + roleVictim * matchRound | subject),
family = binomial, data = df.second);
summary(model.second)
model.second.null <- glmer(choiceAction ~ roleVictim + matchRound + (1 + roleVictim * matchRound | subject),
family = binomial, data = df.second);
anova(model.second, model.second.null)
AIC(model.second)
AIC(model.second.null)
View(df.inflex)
model = glmer(choiceAction ~ roleVictim * matchRound * globalRound + (1 + roleVictim * matchRound * globalRound | subject),
family = binomial, data = df.inflex);
summary(model)
model.null <- model = glmer(choiceAction ~ roleVictim * matchRound + (1 + roleVictim * matchRound | subject),
family = binomial, data = df.inflex);
anova(model, model.null)
model.null <- glmer(choiceAction ~ roleVictim * matchRound + (1 + roleVictim * matchRound | subject),
family = binomial, data = df.inflex);
anova(model, model.null)
model.null <- glmer(choiceAction ~ roleVictim * matchRound + (1 + roleVictim * matchRound * globalRound | subject),
family = binomial, data = df.inflex);
anova(model, model.null)
df.control <- df.inflex %>% group_by(subject) %>% mutate(seenOtherAsThief = any(roleVictim == 0 & oppInflex == 0),
seenOtherAsVictim = any(roleVictim == 1 & oppInflex =- 0))
df.control <- df.inflex %>% group_by(subject) %>% mutate(seenOtherAsThief = any(roleVictim == 0 & oppInflex == 0),
seenOtherAsVictim = any(roleVictim == 1 & oppInflex == 0))
df.control
View(df.control)
View(df.control)
df %>% tbl_df %>% group_by(subject) %>% mutate(seenOtherAsThief = any(roleVictim == 0 & oppInflex == 0),
seenOtherAsVictim = any(roleVictim == 1 & oppInflex == 0))
test <-df %>% tbl_df %>% group_by(subject) %>% mutate(seenOtherAsThief = any(roleVictim == 0 & oppInflex == 0),
seenOtherAsVictim = any(roleVictim == 1 & oppInflex == 0))
test$seenOtherAsThief
df.control <- df %>% tbl_df %>% group_by(subject) %>% mutate(seenOtherAsThief = min(which(roleVictim == 0 & oppInflex == 0)),
seenOtherAsVictim = min(which(roleVictim == 1 & oppInflex == 0)))
View(df.control)
View(df.control)
df.control.before <- df.control %>% filter(globalRound < min(seenOtherAsThief))
model.control.before <- glmer(choiceAction ~ roleVictim * matchRound + (1 + roleVictim * matchRound | subject),
family = binomial, data = df.first);
df.control <- df %>% tbl_df %>% group_by(subject) %>%
mutate(seenOtherAsThief = min(which(roleVictim == 0 & oppInflex == 0)),
seenOtherAsVictim = min(which(roleVictim == 1 & oppInflex == 0))) %>%
filter(oppInflex == 1)
df.control.before <- df.control %>% filter(globalRound < min(seenOtherAsThief))
model.control.before <- glmer(choiceAction ~ roleVictim * matchRound + (1 + roleVictim * matchRound | subject),
family = binomial, data = df.first);
summary(model.control.before)
model.control.before <- glmer(choiceAction ~ roleVictim * matchRound + (1 + roleVictim * matchRound | subject),
family = binomial, data = df.control.before);
model.control.null <- glmer(choiceAction ~ roleVictim + matchRound + (1 + roleVictim * matchRound | subject),
family = binomial, data = df.control.before);
summary(model.control.before)
anova(model.control.before, model.control.null)
df.control.before <- df.control %>% filter(globalRound < min(seenOtherAsThief, seenOtherAsVictim))
model.control.before <- glmer(choiceAction ~ roleVictim * matchRound + (1 + roleVictim * matchRound | subject),
family = binomial, data = df.control.before);
model.control.null <- glmer(choiceAction ~ roleVictim + matchRound + (1 + roleVictim * matchRound | subject),
family = binomial, data = df.control.before);
summary(model.control.before)
anova(model.control.before, model.control.null)
model = glmer(choiceAction ~ roleVictim * matchRound + (1 + roleVictim * matchRound | subject),
family = binomial, data = df.inflex);
model_null = glmer(choiceAction ~ roleVictim + matchRound + (1 + roleVictim * matchRound | subject),
family = binomial, data = df.inflex);
summary(model)
anova(model, model_null)
rm(list=ls())
require(lme4);
require(lmerTest);
require(dplyr);
df <- read.csv('data.csv')
df.inflex <- df %>% filter(oppInflex == 1)
model = glmer(choiceAction ~ roleVictim * matchRound + (1 + roleVictim * matchRound | subject),
family = binomial, data = df.inflex);
model_null = glmer(choiceAction ~ roleVictim + matchRound + (1 + roleVictim * matchRound | subject),
family = binomial, data = df.inflex);
anova(model, model_null)
# Control for what they've seen before
df.control <- df %>% tbl_df %>% group_by(subject) %>%
mutate(seenOtherAsThief = min(which(roleVictim == 0 & oppInflex == 0)),
seenOtherAsVictim = min(which(roleVictim == 1 & oppInflex == 0))) %>%
filter(oppInflex == 1)
df.control.before <- df.control %>% filter(globalRound < min(seenOtherAsThief, seenOtherAsVictim))
model.control.before <- glmer(choiceAction ~ roleVictim * matchRound + (1 + roleVictim * matchRound | subject),
family = binomial, data = df.control.before);
model.control.null <- glmer(choiceAction ~ roleVictim + matchRound + (1 + roleVictim * matchRound | subject),
family = binomial, data = df.control.before);
anova(model.control.before, model.control.null)
summary(model.control.before)
summary(model)
save.image("analysis.RData")
